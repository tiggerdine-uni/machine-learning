{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS985: Assignment 1\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "I wished to explore the problem of using data about a listing to predict its price. Whilst not the most imaginative problem (compared to something like predicting the number of bathrooms a listing has using its postcode), it is realistic. For example, a price predictor could be used by a host to figure out what a fair price would be or by Airbnb to let users sort listings by value (calculated by the difference between the predicted and actual prices). My plan is to use as many different models as possible and compare the error in their predictions.\n",
    "\n",
    "## Summarisation\n",
    "\n",
    "I imported pandas and read the data set into a DataFrame, a 2-dimensonal labeled data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"BristolAirbnbListings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best thing to do when faced with any data analysis problem is to look at the big picture. pandas has a few helpful functions like info(), head() and describe() that can be used to gain insights.\n",
    "\n",
    "shape yields the height and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "info() prints the number of rows and columns, the name and type of each column and the number of non-null values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first impression was that there was a lot of data about each listing, only some of which would be helpful. Most of the column names were self-explanatory.\n",
    "\n",
    "describe() prints the mean, standard deviation, minimum, 25th, 50th and 75th percentiles and maximum of each numerical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made lots of observations off the back of this. For example, half of the listings were priced between £35 and £85 and the majority could be booked for as few as one or two nights.\n",
    "\n",
    "(I changed the value of display.max_columns to None. This option decides how many columns to display. If Python is running in a terminal, the default value is 0, which means \"display as many columns as possible with respect to the width of the terminal\". In other contexs, the default value is 20. None means \"print all the columns\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "head() prints the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This showed me some example listings. Something I didn't understand was why some columns were floats (like latitude) or ints (like price) but other columns that ought to be numbers (like accommodates) were \"objects\".\n",
    "\n",
    "I used value_counts() to explore this. value_counts() returns counts of unique values. In other words, it returns each different value in a column and the number of times it occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"accommodates\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accommodates column contains ints like 2 and 4 but there is some junk like Private room and Entire home/apt stopping it from being a column of ints. The solution to this is cleaning. Cleaning means detecting and correcting (or removing) corrupt or inaccurate records.\n",
    "\n",
    "## Visualisation\n",
    "\n",
    "I used matplotlib to plot some of the data. Visualisation is a good way to understand what the data \"looks like\". [Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet) is an example of why visualisation is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I plotted a \"map\" of dots using latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, I made each dot translucent to discover denser and sparser neighbourhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, I used the price of each listing to control its dot's size and colour. I made a copy of the DataFrame excluding any listings with price > 500 (the listing with price 5000 was causing almost every other listing to be basically the same shade of blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "for x in range(df2.shape[0]):\n",
    "    if df2[\"price\"][x] > 500:\n",
    "        df2 = df2.drop(x)       \n",
    "df2 = df2.reset_index(drop=True)\n",
    "\n",
    "df2.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "    s=df2[\"price\"]/10, label=\"price\", figsize=(10,7),\n",
    "    c=\"price\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
    "    sharex=False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observations I made were\n",
    "\n",
    "* There are more listings closer to the centre\n",
    "* Listings closer to the centre are a bit more expensive\n",
    "* The most expensive listings (yellow, orange and red) can be found both in the centre and on the outskirts\n",
    "* The vast majority of listings cost £100 or less\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Before I went any further, I dropped some columns.\n",
    "\n",
    "* id, name, host_id and host_name because they don't matter\n",
    "* neighbourhood and postcode because latitude and longitude are enough\n",
    "* minimum_nights because almost every listing has 1 <= minimum_nights <= 2\n",
    "* last_review because it doesn't matter\n",
    "* review_scores_* because almost every listing has 9 <= review_scores_* <= 10\n",
    "* calculated_host_listings_count because it's about the host, not the listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"id\", \"name\", \"host_id\", \"host_name\", \"neighbourhood\", \"postcode\", \"minimum_nights\", \"last_review\", \"review_scores_rating\", \"review_scores_accuracy\", \"review_scores_cleanliness\", \"review_scores_checkin\", \"review_scores_communication\", \"review_scores_location\", \"review_scores_value\", \"calculated_host_listings_count\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I checked which columns had any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I iterated over each value in the accommodates column and weeded out any non-ints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(df.shape[0]):\n",
    "    if not df[\"accommodates\"][x].isdigit():\n",
    "        df = df.drop(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two side effects. The first is that even though there are no non-int values in the accommodates column, it's still a column of objects, not ints. I changed the type of the accommodates column to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"accommodates\"] = df[\"accommodates\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second is that indices don't automatically change when rows are dropped. What this means is that if the xth row was dropped, the index x wouldn't point to anything. Another way to think about this is that the for loop used to iterate over each row (for x in range(df.shape[0])) wouldn't work because there would be some rows with indices greater than the number of rows. I solved this problem with reset_index(), making sure to drop the old indices (which would otherwise be preserved in new column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I prepared bathrooms, bedrooms and beds in the same way but first I addressed the null values in those columns by dropping the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"bathrooms\", \"bedrooms\", \"beds\"])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made sure I didn't drop too many rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bathrooms\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bathrooms\"] = df[\"bathrooms\"].astype(float)\n",
    "df[\"bedrooms\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bedrooms\"] = df[\"bedrooms\"].astype(int)\n",
    "df[\"beds\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"beds\"] = df[\"beds\"].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happily, accommodates, bathrooms, bedrooms and beds were all ints/floats. The significance of this was that they could now be used to predict price. I scanned the rest of the columns and found property_type and room_type. It was intuitive that these would correlate with price but there was a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"property_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"room_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text attributes like these can't be easily handled by machine learning algorithms. The most basic option is to convert this from text to numerical data. For example, Apartment = 1, House = 2, etc. This may suggest relationships between values that don't exist. For example, a Bungalow is not \"nine times\" an Apartment. One-hot encoding comes to the rescue. The column to be one-hot encoded is expanded to an array with one binary attribute per category.\n",
    "\n",
    "I didn't want to introduce new columns for things like Boutique hotel and Tent so I shrunk property_type to three values.\n",
    "\n",
    "* anything with \"house\" in it -> \"House\"\n",
    "* anything with \"apartment\" in it -> \"Apartment\"\n",
    "* everything else -> \"Random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(df.shape[0]):\n",
    "    if df[\"property_type\"][x] == \"Townhouse\" or df[\"property_type\"][x] == \"Guesthouse\" or df[\"property_type\"][x] == \"Tiny house\":\n",
    "        df.at[x, \"property_type\"] = \"House\"\n",
    "    elif df[\"property_type\"][x] == \"Serviced apartment\":\n",
    "        df.at[x, \"property_type\"] = \"Apartment\"\n",
    "    if df[\"property_type\"][x] != \"House\" and df[\"property_type\"][x] != \"Apartment\":\n",
    "        df.at[x, \"property_type\"] = \"Other\"\n",
    "df[\"property_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "The correlation between two variables is the strength of the linear relationship between them. For example, if x = y, the correlation between x and y is 1 (perfect correlation). I explored the correlation between price and some other variables I expected to correlate with it and plotted this as a scatter matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "corr_matrix\n",
    "corr_matrix[\"price\"].sort_values(ascending=False)\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "attributes = [\"price\", \"accommodates\", \"bathrooms\",\n",
    "              \"bedrooms\", \"beds\"]\n",
    "scatter_matrix(df[attributes], figsize=(12,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also plotted price's correlation with each of accommodates, bathrooms, bedrooms and beds and adjusted the scales to zoom in on most of the listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\", x=\"accommodates\", y=\"price\", alpha=0.1)\n",
    "plt.axis([0, 10, 0, 400])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\", x=\"bathrooms\", y=\"price\", alpha=0.1)\n",
    "plt.axis([0, 4, 0, 400])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\", x=\"bedrooms\", y=\"price\", alpha=0.1)\n",
    "plt.axis([0, 6, 0, 400])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\", x=\"beds\", y=\"price\", alpha=0.1)\n",
    "plt.axis([0, 6, 0, 400])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot Encoding and Scaling\n",
    "\n",
    "I one-hot encoded the property_type and room_type columns. At the same time, I scaled the rest of the data. Scaling is important because machine learning algorithms often don't perform well when the numerical attributes have very different scales. I used StandardScaler() twhich scales by standardisation (as opposed to min-max scaling). Finally, I combined the categorical and numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_cat = df[\"property_type\"]\n",
    "room_cat = df[\"room_type\"]\n",
    "\n",
    "property_cat_encoded, property_categories = property_cat.factorize()\n",
    "room_cat_encoded, room_categories = room_cat.factorize()\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "property_cat_1hot = encoder.fit_transform(property_cat_encoded.reshape(-1,1))\n",
    "room_cat_1hot = encoder.fit_transform(room_cat_encoded.reshape(-1,1))\n",
    "\n",
    "pcea = property_cat_1hot.toarray()\n",
    "rcea = room_cat_1hot.toarray()\n",
    "\n",
    "df_num = df.drop([\"property_type\", \"room_type\"], axis=1)\n",
    "\n",
    "cat_attribs = [\"property_type\", \"room_type\"]\n",
    "\n",
    "num_attribs = list(df_num)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "df_num[num_attribs] = std_scaler.fit_transform(df_num[num_attribs])\n",
    "\n",
    "property_enc_data = pd.DataFrame(property_cat_1hot.toarray())\n",
    "property_enc_data.columns = property_categories\n",
    "property_enc_data.index = df.index\n",
    "\n",
    "room_enc_data = pd.DataFrame(room_cat_1hot.toarray())\n",
    "room_enc_data.columns = room_categories\n",
    "room_enc_data.index = df.index\n",
    "\n",
    "df_prepared = df_num.join([property_enc_data, room_enc_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(df is easier to type than df_prepared.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews_per_month column still had some null values so I nuked these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"reviews_per_month\"])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was meant to drop a couple of outliers with unrepresentative prices. I later discovered this to be doing nothing because the prices (like everything else) were already scaled. When I moved this code up and the two listings with price > 1500 were dropped, the opposite of what I expected happened. My models performed 50-100% worse. In theory, unrepresentative training data is bad because it causes bias. I was confused by this but couldn't justify making worse predictions so I left the two outliers alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.shape[0])\n",
    "# for x in range(df.shape[0]):\n",
    "#     if df[\"price\"][x] > 1500:\n",
    "#         df = df.drop(x)       \n",
    "# df = df.reset_index(drop=True)\n",
    "# print(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thought it would be a good idea to compare feature importances. There is more than one way to do this but I used RandomForestRegressor's feature_importances_ attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "regr.fit(df.drop([\"price\"], axis=1), df[\"price\"])\n",
    "for x in range(len(list(df.drop([\"price\"], axis=1)))):\n",
    "    print(list(df.drop([\"price\"], axis=1))[x] + \" \" + str(regr.feature_importances_[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, bedrooms and beds are the most important features. Shared room is the least important feature because it only applies to less than 0.1% of the listings. I was a bit surprised that accommodates and bathrooms weren't more important. I was even more surprised that House, Apartment and Other were basically a waste of time. I could and, in hindsight, should have seen this coming by doing some visualisation to compare the prices of houses and apartments. Rather than going back and pretending I did, I'll fess up to this mistake.\n",
    "\n",
    "## Creating Training and Test Sets\n",
    "\n",
    "Evaluating models on training data alone leads to biased results. To avoid this trap, I split the data into training and test sets. What this means is that models can be trained on 80% of the data and tested on the other 20%. I also dropped price from both sets into test_set_labels and train_set_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)\n",
    "test_set.head()\n",
    "train_set.head()\n",
    "\n",
    "test_set_labels = test_set[\"price\"].copy()\n",
    "test_set = test_set.drop(\"price\", axis=1)\n",
    "train_set_labels = train_set[\"price\"].copy()\n",
    "train_set = train_set.drop(\"price\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "First, I used was linear regression. This is, as far as I know, the most basic regression model. It tries to find the line of best fit through the data. I trained it on the training set and tried it on a few examples from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(train_set, train_set_labels)\n",
    "\n",
    "some_data = test_set.iloc[:5]\n",
    "some_labels = test_set_labels.iloc[:5]\n",
    "\n",
    "print(\"Predictions:\", lin_reg.predict(some_data))\n",
    "\n",
    "print(\"Labels:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I calculated the root mean square error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "predictions = lin_reg.predict(test_set)\n",
    "\n",
    "lin_mse = mean_squared_error(test_set_labels, predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also used cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(lin_reg, test_set, test_set_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error was lower in 8 of the 10 cases, suggesting this train/test split was \"unlucky\".\n",
    "\n",
    "## Decision Tree Regression\n",
    "\n",
    "Second, I used decision tree regression, so named because it uses a decision tree to decide what it thinks a listing's price is based on its other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg.fit(train_set, train_set_labels)\n",
    "tree_predict = tree_reg.predict(test_set)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(test_set_labels, tree_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I adjusted max_depth by trial and error and found a value of 4 to be optimal..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor(max_depth=4, random_state=42)\n",
    "tree_reg.fit(train_set, train_set_labels)\n",
    "tree_predict = tree_reg.predict(test_set)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(test_set_labels, tree_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and used cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(tree_reg, test_set, test_set_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(rmse_scores)\n",
    "print(np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression\n",
    "\n",
    "Third, I used support vector regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "svm_reg = LinearSVR(epsilon=1.5, random_state=42)\n",
    "svm_reg.fit(train_set, train_set_labels)\n",
    "svm_predict = svm_reg.predict(test_set)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(test_set_labels, svm_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I adjusted epsilon by trial and error and found a value of 1.5 to be optimal..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_reg = LinearSVR(epsilon=0.4, random_state=42)\n",
    "svm_reg.fit(train_set, train_set_labels)\n",
    "svm_predict = svm_reg.predict(test_set)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(test_set_labels, svm_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and used cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(svm_reg, test_set, test_set_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression\n",
    "\n",
    "Fourth, I used random forest regression. A random forest is an ensemble of decision trees which introduces extra randomness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(max_depth=2, random_state=42, n_estimators=100)\n",
    "rf_reg.fit(train_set, train_set_labels)\n",
    "predictions = rf_reg.predict(test_set)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(test_set_labels, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I adjusted max_dep and n_estimators by trial and error and found values of 3 and 200 to be optimal..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(max_depth=3, random_state=42, n_estimators=200)\n",
    "rf_reg.fit(train_set, train_set_labels)\n",
    "predictions = rf_reg.predict(test_set)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(test_set_labels, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and used cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rf_reg, test_set, test_set_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(rmse_scores)\n",
    "print(np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something that surprised me was that despite my optimising both, the random forest regressor did not beat the lone decision tree regressor. This is why cross validation matters. Comparing the cross validation scores of the decision tree and random forest regressors, I found the random forest regressor to be better in 9 of the 10 cases and have a significantly better mean (0.285 compared to 0.356).\n",
    "\n",
    "With that qualification in mind, here are the scores.\n",
    "\n",
    "| Regression     | RMSE  |\n",
    "| -------------- | ----- |\n",
    "| Decision Tree  | 0.287 |\n",
    "| Random Forest  | 0.297 |\n",
    "| Support Vector | 0.307 |\n",
    "| Linear         | 0.332 |\n",
    "\n",
    "In conclusion, all four worked quite well. Maybe the difference would have been bigger if the data set was bigger or more time was spent experimenting with the paramaters of the more complex models. This assignment helped me to understand not only the four different types of regression I used to solve the problem but also how to prepare data for them. There are some things I would have done differently and some things I would have done in a different order. I did like Jupyter Notebook a lot so hopefully I have cause to use it again in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
